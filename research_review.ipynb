{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research review: three developments in AI planning and search\n",
    "\n",
    "## 1) Partial order planning\n",
    "Partial order planning (POP) does not search the space of states, but the space of plans. In the most simple form, a plan is a totally ordered sequence of actions. In the context of the air cargo problems from our project, a plan to bring two cargo items c1 and c2 from SFO to JFK might look like this:\n",
    "\n",
    "    Load(c1, plane, SFO); Load(c2, plane, SFO); Fly(plane, SFO, JFK); Unload(c1, plane, JFK); Unload(c2, plane, JFK)\n",
    "\n",
    "In this plan, some steps are interchangeable (it does not matter which cargo item is loaded first), and others are not (flying an empty plane will not bring the cargo anywhere). POP takes account of this by replacing the total ordering of the sequence by a partial ordering, e.g.\n",
    "\n",
    "    Load(c1, plane, SFO) < Fly(plane, SFO, JFK) and Load(c2, plane, SFO) < Fly(plane, SFO, JFK)\n",
    "\n",
    "POP uses a concept called _causal link_ (introduced in Tate (1977)) to remember which action was added to a plan in order to reach which subgoal. When a new action is added to a plan, we can check whether this action _threatens_ a causal link. If this is the case, the partial ordering can be extended by specifying that the new action has to be executed before or after some other actions.\n",
    "\n",
    "POP was the predominant planning approach from the mid-seventies until the mid-nineties of the last century. Then faster state-space search algorithms (see below) were developed, and POP went out of fashion. It was revived by Nguyen and Kambhampati (2001) who transferred the improvements in heuristics to POP.\n",
    "\n",
    "## 2) State-space planning with heuristics\n",
    "Forward search in the space of states gained a lot of popularity when good domain-independent heuristics were developed. The first such system was HSP (Bonet et al. 1997). The heuristic used by HSP estimates the distance from a state to the goal by considering a _relaxed problem:_ the delete lists of actions are ignored. The heuristic assumes that the elements of the goal state are reached independently, i.e. that the distance to the goal state equals the sum of the distances to each element in the goal state.\n",
    "\n",
    "Hoffmann's fast-forward planning system (Hoffmann 2001) is based on this approach, but makes the following improvements:\n",
    "\n",
    "* A heuristic based on the Graphplan algorithm is used. This heuristic takes positive interactions into account and thus provides smaller, more accurate estimates.\n",
    "\n",
    "* Search is faster because fewer states are considered. From a given state, the algorithm moves to a successor state with a better heuristic value. If none of the successors has a better heuristic value, all successors' successors are considered, etc. - until a state with a better heuristic is found. Hoffmann calls this _enforced hill climbing._\n",
    "\n",
    "* A concept of _helpful actions_ is used. Actions that seem not helpful are not considered. If this does not lead to a solution, all actions are considered. This finds solutions faster in most cases.\n",
    "\n",
    "\n",
    "## 3) Real world applications: acting instead of planning\n",
    "Classical planning assumes a fixed set of states and deterministic actions that have preconditions and effects. Planning is about finding a sequence of actions to reach a specific goal state. For many real world applications, this approach is too theroretical. Ghallab et al. (2014) suggest to focus research more on _acting_ instead of planning. Acting is the purpose of planning. Although planning is one important requirement for acting, it is not sufficient. The authors use two examples to illustrate their point: the management of a large harbor, and a robot whose purpose is to move objects in an open environment. For automated systems like these the following points are important:\n",
    "\n",
    "* Hierarchies of components: one component receives tasks from the components above it. To executes this task the component can create or update plans, receive and analyze sensor data, or delegate subtasks to components below it.\n",
    "\n",
    "* Continual planning: an actor in the real world needs to interact with its environment and update plans continually. For some  events it is not possible or feasible to plan ahead of time. Instead the actor should adjust its plan.\n",
    "\n",
    "* Uncertainty: in the real world an actor's environment is dynamic. Unexpected events may happen, or actions may not have the intended effect.\n",
    "\n",
    "A system that takes these aspects into account needs to be more complex than the systems used in classical planning: It has to have a better understanding of its environment.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "__Bonet,__ B., Loerincs G., and Geffner, H. (1997). _A robust and fast action selection mechanism for planning._ Proc. AAAI-97, 714-719.\n",
    "\n",
    "__Ghallab,__ M., Nau, D., and Traverso, P. (2014). _The actor's view of automated planning and acting: A position paper._ Artificial Intelligence 208.\n",
    "\n",
    "__Hoffmann,__ J. (2001). FF: _The fast-forward planning system._ AI Magazine 22(3), 57-62.\n",
    "\n",
    "__Nguyen,__ X. and Kambhampati, S. (2001). _Reviving partial order planning. IJCAI-01,_ 459-464.\n",
    "\n",
    "__Russell,__ S. J. and Norvig, P. (2011). Artificial Intelligence - A Modern Approach (Third Edition), Chapters 10 & 11. Pearson.\n",
    "\n",
    "__Tate,__ A. (1977). _Generating project networks._ Proc. 5th Int. Joint Conf. on AI, 888-893.\n",
    "\n",
    "__Weld,__ D. S. (1994). _An introduction to least commitment planning._ AI Magazine 15(4), 27-61."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aind]",
   "language": "python",
   "name": "conda-env-aind-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
